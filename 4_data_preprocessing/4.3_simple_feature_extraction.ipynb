{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8928744",
   "metadata": {},
   "source": [
    "# Simple Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ca7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parents[0]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from utils.paths import CLEANED_DIR, EXTRACTED_FEATURES_DIR, RAN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "root_data_folder = CLEANED_DIR\n",
    "ran_scores_df = pd.read_csv(RAN_DIR / \"RAN_HashTable.csv\")\n",
    "\n",
    "# Container for features\n",
    "features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facfaf4b",
   "metadata": {},
   "source": [
    "### Prep Feature Extraction\n",
    "- impute missing ages based on average of category\n",
    "- filter rows -> use ONLY FN.*Start\n",
    "- compute mean durations for fixation or saccades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce009e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means for imputation\n",
    "fruitninja_age_mean = 24\n",
    "dyscover_age_mean = 6\n",
    "   \n",
    "def process_annotated_files(files, var, folder_name, participant_folder):\n",
    "    \"\"\"\n",
    "    Process annotated files to compute features. Use ONLY the FN.*Start events.\n",
    "    This function is called for each participant folder.\n",
    "    \n",
    "    Args:\n",
    "        files (list): List of files in the participant folder.\n",
    "        var (str): The variable to process, either 'blinks', 'fixations', 'gaze', 'imu' or 'saccades'.\n",
    "    \"\"\"\n",
    "    filename_start = f'annotated_{var}' \n",
    "    filtered_files = [f for f in files if f.startswith(filename_start)]\n",
    "   \n",
    "    if len(filtered_files) == 0:\n",
    "        print(f\"Missing annotated files in folder {folder_name}\")\n",
    "\n",
    "    first_file = filtered_files[0]\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(os.path.join(participant_folder, first_file), low_memory=False)\n",
    "\n",
    "    # Filter event_name\n",
    "    event_pattern = 'FN.*Start'\n",
    "    fn_df = df[df['event_name'].fillna('').str.contains(event_pattern)]\n",
    "    \n",
    "    return fn_df\n",
    "\n",
    "# Function to compute fixations or saccades per minute\n",
    "def compute_per_min_var(df):\n",
    "    \"\"\"\n",
    "    Compute the average number of events (rows) per minute across all trials.\n",
    "\n",
    "    For each trial (grouped by 'event_name'), this function calculates the duration in minutes\n",
    "    using the 'start timestamp [ns]' and 'end timestamp [ns]' columns. It then computes the number\n",
    "    of rows per minute for each trial and returns the mean value across all trials.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataframe containing at least the columns:\n",
    "                           - 'event_name' (used to group trials),\n",
    "                           - 'start timestamp [ns]',\n",
    "                           - 'end timestamp [ns]'.\n",
    "\n",
    "    Returns:\n",
    "        float: The mean number of data points (rows) per minute across all trials.\n",
    "               Returns 0 if no valid trials are found.\n",
    "    \"\"\"\n",
    "    per_min_list = []\n",
    "    for trial_name, trial_df in df.groupby('event_name'):\n",
    "        start_ts = trial_df['start timestamp [ns]'].min()\n",
    "        end_ts = trial_df['end timestamp [ns]'].max()\n",
    "        duration_min = (end_ts - start_ts) / (60 * 1e9)\n",
    "        if duration_min > 0:\n",
    "            num_var = len(trial_df)\n",
    "            var_per_min = num_var / duration_min\n",
    "            per_min_list.append(var_per_min)\n",
    "            \n",
    "    # Compute participant means\n",
    "    mean_per_min = sum(per_min_list) / len(per_min_list) if per_min_list else 0\n",
    "    return mean_per_min "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25333935",
   "metadata": {},
   "source": [
    "### Standard Features\n",
    "['mean_fix_duration', 'median_fix_duration', 'mean_saccade_length',\n",
    "       'median_saccade_length', 'mean_blink_duration', 'median_blink_duration',\n",
    "       'num_fixations_per_min', 'num_blinks_per_min', 'num_saccades_per_min',\n",
    "       'age', 'ran_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e905300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-29_15-55-26\n",
      "Skipping folder ERROR_Filtered_DysCover_2024-06-06_14-41-34-85e33d1a_3d679ae7_0.0-1568.742_yolo11 (ERROR_)\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-17_11-52-56\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-03-31_09-49-48\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-28_15-30-49\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-03-31_10-29-39\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-15_10-47-26\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-23_11-39-23\n",
      "Skipping folder ERROR_Filtered_Adult_Spring_2025-04-18_11-40-33-4349baf8_447aca05_0.0-1631.454_yolo11 (ERROR_)\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-24_16-47-08\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-18_10-30-25\n",
      "No RAN score found for HASH: 2024-03-27_11-19-10 in folder Filtered_Fruit_Ninja_2024-03-27_11-19-10-d39c49e2_365a25a9_0.0-1061.854_yolo11\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-05-02_13-02-10\n",
      "Imputed age for group 'dyscover' as 6 for HASH 2024-06-06_08-57-56\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-05-05_15-33-21\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-22_15-01-50\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-28_18-09-34\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-17_08-06-40\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-15_09-22-00\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-15_15-13-11\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-15_16-33-38\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-29_14-39-36\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-15_13-05-00\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-22_11-23-16\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-18_08-55-43\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-16_10-15-13\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-05-08_09-09-51\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-28_08-36-20\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-22_09-53-23\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-16_11-29-18\n",
      "Imputed age for group 'adultspring' as 24 for HASH 2025-04-25_15-41-32\n"
     ]
    }
   ],
   "source": [
    "# Loop through participant folders\n",
    "for folder_name in os.listdir(root_data_folder):\n",
    "\n",
    "    if folder_name.startswith('ERROR_'):\n",
    "        print(f\"Skipping folder {folder_name} (ERROR_)\")\n",
    "        continue\n",
    "\n",
    "    participant_folder = os.path.join(root_data_folder, folder_name)\n",
    "\n",
    "    if not os.path.isdir(participant_folder):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Extract HASH timestamp from folder name\n",
    "        match = re.search(r'\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}', folder_name)\n",
    "        if match:\n",
    "            hash_str = match.group(0)\n",
    "        else:\n",
    "            print(f\"No HASH match for folder: {folder_name}\")\n",
    "            continue\n",
    "\n",
    "        # Find RAN row where HASH column CONTAINS the timestamp\n",
    "        ran_row = ran_scores_df[ran_scores_df['HASH'].str.contains(hash_str, na=False)]\n",
    "        if ran_row.empty:\n",
    "            print(f\"No RAN score found for HASH: {hash_str} in folder {folder_name}\")\n",
    "            continue\n",
    "\n",
    "        ran_score = ran_row['objectPerSecond'].values[0]\n",
    "\n",
    "        # Impute age\n",
    "        raw_age = ran_row['Age'].values[0]\n",
    "        group = ran_row['Group'].values[0].strip().lower()\n",
    "\n",
    "        if pd.isna(raw_age):\n",
    "            if group == 'dyscover':\n",
    "                age = dyscover_age_mean\n",
    "                print(f\"Imputed age for group '{group}' as {age} for HASH {hash_str}\")\n",
    "            elif group in ['fruitninja', 'adultspring']:\n",
    "                age = fruitninja_age_mean\n",
    "                print(f\"Imputed age for group '{group}' as {age} for HASH {hash_str}\")\n",
    "        else:\n",
    "            age = raw_age\n",
    "\n",
    "        # List files in participant folder\n",
    "        files = os.listdir(participant_folder)\n",
    "\n",
    "        fix_fn_df = process_annotated_files(files, 'fixations', folder_name, participant_folder)\n",
    "        sacc_fn_df = process_annotated_files(files, 'saccades', folder_name, participant_folder)\n",
    "        blinks_fn_df = process_annotated_files(files, 'blinks', folder_name, participant_folder)\n",
    "\n",
    "        # Per trial fixations or saccades per minute        \n",
    "        mean_fix_per_min = compute_per_min_var(fix_fn_df)\n",
    "        mean_sacc_per_min = compute_per_min_var(sacc_fn_df)\n",
    "        mean_blinks_per_min = compute_per_min_var(blinks_fn_df)\n",
    "\n",
    "        # Store features\n",
    "        features.append({\n",
    "            'participant_folder': folder_name,\n",
    "            'HASH': hash_str,\n",
    "            'group': group,\n",
    "            'mean_fix_duration': fix_fn_df['duration [ms]'].mean(),\n",
    "            'median_fix_duration': fix_fn_df['duration [ms]'].median(),\n",
    "            'mean_saccade_length': sacc_fn_df['amplitude [px]'].mean(),\n",
    "            'median_saccade_length': sacc_fn_df['amplitude [px]'].median(),\n",
    "            'mean_blink_duration': blinks_fn_df['duration [ms]'].mean(),\n",
    "            'median_blink_duration': blinks_fn_df['duration [ms]'].median(),\n",
    "            'num_fixations_per_min': mean_fix_per_min,\n",
    "            'num_blinks_per_min': mean_blinks_per_min,\n",
    "            'num_saccades_per_min': mean_sacc_per_min,\n",
    "            'age': age,\n",
    "            'ran_score': ran_score\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {folder_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78078af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 58\n"
     ]
    }
   ],
   "source": [
    "# --- Final dataframe ---\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "features_df_numeric = features_df.select_dtypes(include=['number'])\n",
    "print('N:', len(features_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5295bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fix_duration', 'median_fix_duration', 'mean_saccade_length',\n",
       "       'median_saccade_length', 'mean_blink_duration', 'median_blink_duration',\n",
       "       'num_fixations_per_min', 'num_blinks_per_min', 'num_saccades_per_min',\n",
       "       'age', 'ran_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0291a78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: /HOME/lecomteo/thesis/master_thesis/data/processed/extracted_features/simple_feature_extraction.csv. Not overwriting.\n"
     ]
    }
   ],
   "source": [
    "# save full CSV\n",
    "output_csv_path = EXTRACTED_FEATURES_DIR / 'simple_feature_extraction.csv'\n",
    "overwrite = False  # Set to True if you want to overwrite existing files\n",
    "\n",
    "if not os.path.exists(output_csv_path) or overwrite:\n",
    "    features_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Features saved to {output_csv_path}\")\n",
    "\n",
    "else:\n",
    "    print(f\"File already exists: {output_csv_path}. Not overwriting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d8be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
